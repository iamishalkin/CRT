{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../')\n",
    "from av_parser import AVDBParser\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from accuracy import Accuracy\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_root, file_list, max_num_clips=0, max_num_samples=50):\n",
    "    dataset_parser = AVDBParser(dataset_root, os.path.join(dataset_root, file_list),\n",
    "                                max_num_clips=max_num_clips, max_num_samples=max_num_samples,\n",
    "                                ungroup=False, load_image=True)\n",
    "    data = dataset_parser.get_data()\n",
    "    print('clips count:', len(data))\n",
    "    print('frames count:', dataset_parser.get_dataset_size())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_features(data):\n",
    "    orb = cv2.ORB_create()\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    progresser = tqdm(iterable=range(0, len(data)),\n",
    "                      desc='calc video features',\n",
    "                      total=len(data),\n",
    "                      unit='files')\n",
    "\n",
    "    feat, targets = [], []\n",
    "    for i in progresser:\n",
    "        clip = data[i]\n",
    "\n",
    "        rm_list = []\n",
    "        for sample in clip.data_samples:\n",
    "            landmarks = get_keypoints(sample.landmarks)\n",
    "            image = sample.image\n",
    "            image_features = sift.compute(image, landmarks)[1]\n",
    "            feat.append(image_features)\n",
    "            targets.append(sample.labels)\n",
    "            # TODO: придумайте способы вычисления признаков по изображению с использованием ключевых точек\n",
    "            # используйте библиотеку OpenCV\n",
    "\n",
    "        for sample in rm_list:\n",
    "            clip.data_samples.remove(sample)\n",
    "\n",
    "    print('feat count:', len(feat))\n",
    "    return np.asarray(feat, dtype=np.float32), np.asarray(targets, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints(landmarks):\n",
    "    landmarks_df = pd.DataFrame(landmarks, columns=['x', 'y'])\n",
    "    return landmarks_df.apply(lambda x: cv2.KeyPoint(int(x.x), int(x.y), 1), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_keys = get_keypoints(t2.landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 128)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift.compute(t2.image, t2_keys)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.cornerHarris(cv2.cvtColor(t2.image, cv2.COLOR_BGR2GRAY), 1, 1, 0.2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeyPoint 000001DB0EC4EF60>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.KeyPoint(2, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(kps, descs) = sift.detectAndCompute(t2.image, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1 =kps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kp1.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'x' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-cdd839055a07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyPoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Required argument 'x' (pos 1) not found"
     ]
    }
   ],
   "source": [
    "cv2.KeyPoint.(pt=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected cv::KeyPoint for argument 'keypoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-3d1d97b6ccdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Expected cv::KeyPoint for argument 'keypoints'"
     ]
    }
   ],
   "source": [
    "sift.compute(t2.image, np.array(t2.landmarks, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'exp_1'\n",
    "max_num_clips = 50 # загружайте только часть данных для отладки кода\n",
    "use_dump = False # используйте dump для быстрой загрузки рассчитанных фич из файла\n",
    "\n",
    "# dataset dir\n",
    "base_dir = 'C:/Users/ipmstud/Desktop/crt'\n",
    "if 1:\n",
    "    train_dataset_root = base_dir + '/Video'\n",
    "    train_file_list = base_dir + '/train_data_with_landmarks.txt'\n",
    "    test_dataset_root = base_dir + '/Video'\n",
    "    test_file_list = base_dir + '/test_data_with_landmarks.txt'\n",
    "elif 1:\n",
    "    train_dataset_root = base_dir + '/OMGEmotionChallenge-master/omg_TrainVideos/preproc/frames'\n",
    "    train_file_list = base_dir + '/OMGEmotionChallenge-master/omg_TrainVideos/preproc/train_data_with_landmarks.txt'\n",
    "    test_dataset_root =base_dir + '/OMGEmotionChallenge-master/omg_ValidVideos/preproc/frames'\n",
    "    test_file_list = base_dir + '/OMGEmotionChallenge-master/omg_ValidVideos/preproc/valid_data_with_landmarks.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVDB meta parsing: 100%|████████████████████████████████████████████████████| 33087/33087 [03:15<00:00, 169.55images/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clips count: 1200\n",
      "frames count: 33087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVDB meta parsing: 100%|██████████████████████████████████████████████████████| 6839/6839 [00:44<00:00, 155.13images/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clips count: 240\n",
      "frames count: 6839\n"
     ]
    }
   ],
   "source": [
    "if not use_dump:\n",
    "    # load dataset\n",
    "    train_data = get_data(train_dataset_root, train_file_list, max_num_clips=0)\n",
    "    test_data = get_data(test_dataset_root, test_file_list, max_num_clips=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calc video features: 100%|██████████████████████████████████████████████████████| 1200/1200 [02:43<00:00,  7.35files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat count: 33087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calc video features: 100%|████████████████████████████████████████████████████████| 240/240 [01:46<00:00,  2.25files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat count: 6839\n"
     ]
    }
   ],
   "source": [
    "train_feat, train_targets = calc_features(train_data)\n",
    "test_feat, test_targets = calc_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(X_train, X_test, y_train, y_test, accuracy_fn, pca_dim):\n",
    "    if pca_dim > 0:\n",
    "        pca = PCA(n_components=pca_dim)\n",
    "        X_train = pca.fit_tranform()\n",
    "        X_test = \n",
    "        # TODO: выполните сокращение размерности признаков с использованием PCA\n",
    "\n",
    "    # shuffle\n",
    "    combined = list(zip(X_train, y_train))\n",
    "    random.shuffle(combined)\n",
    "    X_train[:], y_train[:] = zip(*combined)\n",
    "\n",
    "    # TODO: используйте классификаторы из sklearn\n",
    "    model = RandomForestClassifier(n_estimators=50)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict\n",
    "    accuracy_fn.by_frames(y_pred)\n",
    "    accuracy_fn.by_clips(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    if not use_dump:\n",
    "        # load dataset\n",
    "        train_data = get_data(train_dataset_root, train_file_list, max_num_clips=0)\n",
    "        test_data = get_data(test_dataset_root, test_file_list, max_num_clips=0)\n",
    "\n",
    "        # get features\n",
    "        train_feat, train_targets = calc_features(train_data)\n",
    "        test_feat, test_targets = calc_features(test_data)\n",
    "\n",
    "        accuracy_fn = Accuracy(test_data, experiment_name=experiment_name)\n",
    "\n",
    "        #with open(experiment_name + '.pickle', 'wb') as f:\n",
    "        #    pickle.dump([train_feat, train_targets, test_feat, test_targets, accuracy_fn], f, protocol=2)\n",
    "    else:\n",
    "        with open(experiment_name + '.pickle', 'rb') as f:\n",
    "            train_feat, train_targets, test_feat, test_targets, accuracy_fn = pickle.load(f)\n",
    "\n",
    "    # run classifiers\n",
    "    classification(train_feat, test_feat, train_targets, test_targets, accuracy_fn=accuracy_fn, pca_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
